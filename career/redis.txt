为什么要用redis而不用map做缓存?
缓存分为本地缓存和分布式缓存。以java为例,使用自带的map或者guava实现的是本地缓存,
最主要的特点是轻量以及快速,生命周期随着jvm的销毁而结束,
并且在多实例的情况下,每个实例都需要各自保存一份缓存,缓存不具有一致性。


redis:基于内存高速,LUA脚本整体执行原子性
	调优:数据量相同情况下K,V的长度大操作效率越慢(保存的字段是否都要用、可进行字段的拆分)
		lazy free(延时删除):使用BIO(background I/O)单独一条线程处理,减少删除对redis主线程的阻塞,
						   可通过配置文件进行实现,建议开启lazyfree-lazy-flush、-expire、-server-del
		根据业务需要设置合理过期时间
		尽可能少的在redis中进行并集、交集、排序的操作(放在逻辑代码处执行)
		开启慢日志查询:slow-log-slower-than 来配置记录阈值时间(单位毫秒)
		根据业务可以使用pipeline进行批处理,减少与redis的交互时间
			通过Jedis实例得到Pipeline对象建立链接,set方法将所有的command命令刷入输出流通过sync统一调用flush命令将消息发出
		配置hz 10(默认值推荐使用),避免大量数据同时消失造成缓存雪崩


使用redis缓存:
	解决缓存穿透:空结果缓存
	解决缓存雪崩:缓存预热、错开失效时间
	解决缓存击穿:加锁
	缓存数据一致性:
		双写模式:写数据库更新缓存
		失效模式:写数据库删除缓存(推荐)
			当高并发时,要删除的缓存数据被读到会出现脏数据:将操作放入MQ队列但是性能直线下降违背了使用缓存的目的,性能不升反降
			缓存数据+过期时间可以解决大部分业务对缓存的要求:缓存的数据本身就不要求实时性是不常改变的只是读频繁
			不应该过度的设计增加系统的复杂程度,应根据业务结合性能和数据一致性考虑不同的设计方案


缓存穿透:数据库、缓存都没有导致每次访问都将压力挂到数据库服务器导致服务崩溃
	缓存空数据:需要占用内存空间、空数据要设置过期时间可能导致数据更新后DB与Redis不一致
	布隆过滤器:通过多个hash函数得到数据位置,如果有多个函数运算得到位值都为1表示可能存在,
			  如果有一个位值是0表示一定不存在,如果hahs运算个数越多表示可能性越大但是更浪费内存,推荐误差率选3%
缓存击穿:单个热点数据过了有效时间,大量请求落在了数据库上导致数据库服务崩溃
	热点数据永不过期
缓存雪崩:缓存数据在同一时间批量失效,数据库接收大量的请求而崩溃
	缓存数据分布部署
	使用随机时间使缓存时间不在同一时间过期
	热点数据永不过期
	使用服务熔断降级、限流等手段
无论是上面3种都建议使用队列,拒绝大量请求涌入、分布式锁避免后端数据服务被冲击


lua脚本:原子性、高性能、逻辑可控
持久化:
	RDB:快照持久化文件
		save:阻塞方式进行持久化
		bgsave:从主线程fork出一个子线程,是非阻塞的(可通过配置文件进行配置:满足时间内key变化的次数就触发)
		save 900 1 	---- 900s内变化一次触发
		save 300 10 ---- 300s内变化10次触发
	AOF:通过保存redis服务器执行的写命令(默认关闭,需要开启配置)
		文件同步:保证集群的一致性(always、everysec推荐使用性能可靠性居中、no)
		文件重写压缩:降低AOF文件所占磁盘空间大小,同时提升服务器启动性能(不必要的命令不必执行)
	RDB、AOF一般会同时使用,保证数据的可靠性


主从复制:数据只能从主节点同步到从节点,主节点可读可写,从节点只提供读操作
	在这种模式下只有一个主节点,一旦主节点宕机就无法进行写操作了,也就是说主从复制这种模式并没有实现高可用
哨兵模式: 通过一个哨兵进程来监视集群节点
	当Master节点挂掉,会通过vote算法从Slave节点中选取出一个新的节点作为Master接待你继续工作
	任何一个数据的增删改都需要Master节点处理,保障了数据的一致性符合CAP定理中的CP原则
	主从服务器的数据要经常进行全量复制造成性能的下降
	当主节点宕机后,从服务器切换成主服务器的那段时间服务是不可用的,降低了高可用性
内置集群:实现数据分片保存, 通过任意入口进行Redis的跳转避免了哨兵模式写节点单点故障
	数据分片存储某一个节点挂掉不影响其他节点使用
	局部Master节点挂掉后,局部Slave会成为新的Master继续提供服务


缓存与数据一致性:
	延时双删:无法预估需要延时的时间
	订阅binglog日志的同步机制:
		数据库主节点的操作会产生binglog日志
		Canal中间件通过伪装成从节点获取主节点的binglog日志
		Canal将binlog日志进行解析后推动给MQ队列
		读操作通过手动推送消息到MQ队列
		通过消费消息队列来有序操作Redis


Redis批量操作:
	批量命令:mset、mget,原子性操作
	管道模式:性能快、无序、非原子性
	事务模式:原子性、比pipeline慢比普通模式快
	lua脚本:自定义执行顺序、原子性、比pipeline慢比普通模式快、有长度限制
总结:能批量就批量、不能的话需执行顺序用lua、不需要顺序用事务、无需原子性追求速度用管道


-----------------------------------------------------------

分布式解决方案:
	XA(两阶段提交)
		准备阶段:所有的RM(事务分支)都ACK发给TM(事务协调者)ok
		提交阶段:TM根据每个RM的反馈决定是否提交事务
		优点:数据的强一致性
		缺点:事务协调者挂了参与者收不到提交或回滚的通知、只要有一个事务分支阻塞则整体阻塞
	TCC(Try+Comfirm+Cancel):需要编写补偿代码,也要确保补偿代码不能引入新的事务,应保证操作的原子性
		优点:解决了二阶段提交的同步阻塞问题
		缺点:代码耦合度增加
		先来 Try ⼀下,不要把业务逻辑完成,如果 Try 都 ok,也就是说大概率各服务是可用状态再执⾏各个服务的 Confirm 逻辑,
		如果 Try 阶段某个服务就失败了,此时就⾃动执⾏各个服务的 Cancel 逻辑,把之前的 Try 逻辑都回滚保证⼤家要么⼀起成功,要么⼀起失败。
	SAGA:有代码侵入
		一个分布式事务拆分成多个本地事务
		本地事务都有相应的执行模块和补偿模块
		事务管理器负责在事务失败时调度执行补偿逻辑
	消息队列:发送RPC到MQ成功返回失败回滚，需要用到RocketMQ的事务消息特性

redis:
	redis原生API-setNX:
		过期释放锁
		设置过期时间必须满足原子性
		加锁要指定uuid,删除时判断是否是自己的uuid
		删除时保证原子性,使用redis+lua脚本
		原生API不支持可重入,无法实现过期自动续期
	redisson:他是一个为客户端,自带扩容机制pub/sub需要通知唤醒线程性能有损耗
		redisson的看门狗机制会定时检测是否还持有锁,并做续期处理
		当多个请求到达redis时一个线程获取了锁其他线程就无法操作,然后串行依次执行
		但是请求过多必然会一直阻塞,可用对库存采用分段锁1000的总量可用分20份:stock_01、stock_02、、、
		有⼀个坑⼤家⼀定要注意：就是如果某个下单请求加锁,然后发现这个分段库存⾥的库存不⾜了
		这时你得⾃动释放锁,然后⽴⻢换下⼀个分段库存,再次尝试加锁后尝试处理

zk:zk上的一个节点就是一把锁,2个线程都要获取着把锁
	2个线程上来依次创建锁节点下的⼀个临时顺序节点
	如果⾃⼰不是第⼀个节点,就对⾃⼰上⼀个节点加监听器
	只要上⼀个节点释放锁,⾃⼰就排到前⾯去了,相当于是⼀个排队机制。
	如果某个客户端创建临时顺序节点之后,不⼩⼼⾃⼰宕机了也没关系,zk 感知到那个客户端宕机,
	会⾃动删除对应的临时顺序节点,相当于⾃动释放锁,或者是⾃动取消⾃⼰的排队。

分布式全局id:独立数据库自增id、uuid(性能差)、系统时间戳+用户id+业务编码、snowflake、美团Leaf

分布式计算系统:分布式存储+分布式计算
每台机器的计算结果出来之后,就可以进⾏综合性的汇总,然后就可以拿到最终的⼀个分析结果

-----------------------------------------------------------

被volatile修饰的变量:private volatile int data = 0; 
当线程1改变时会就会在修改了自己本地工作内存后将新的值刷回主内存,此时如果有其他线程工作内存中有这个data的变量缓存,
也会强制让其工作内存中的变量缓存直接过期,此时如果线程2需要data值时会发现已经过期而去主内存中加载最新的值。
volatile主要作用是保证可⻅性(一个线程修改变量值之后,其他线程立⻢可以读到最新的值)以及有序性,不负责原子性。
volatile关键字主要⽤于解决变量在多个线程之间的可⻅性,⽽ synchronized关键字解决的是多个线程之间访问资源的同步性

ArrayList 默认情况下肯定是线程不安全的,是⽤ ReadWriteLock 读写锁的⽅式来控制
读请求和写请求之间互斥,写请求和写请求也是互斥的。此时⼤量的读操作过来是不是就会被偶尔的写操作阻塞住
这个时候就要引⼊ CopyOnWrite:写数据的时候利⽤拷⻉的副本来执⾏(加锁不会出现多个副本),
配合上 volatile 关键字会对读线程可⻅,⼤家都能看到最新的数组了。

原⼦类都存放在 java.util.concurrent.atomic 下,⼀个操作⼀旦开始,就不会被其他线程⼲扰
AtomicInteger data = new AtomicInteger(0); data.getAndIncrement();
使用了CAS(先比较再设值)先获取一个值,然后发起CAS,比较这个值被人改过没？如果没有,就更改值。
通过这个机制,不需要加锁这么重量级的机制,也可以用轻量级的方式实现多个线程安全的并发的修改某个数值,
不会导致线程阻塞，但是因为重试是通过自旋实现的，所以仍然会占用CPU时间
但是⼤量的线程同时并发修改⼀个AtomicInteger,可能有很多线程会不停的⾃旋,
进⼊⼀个⽆限重复的循环中,Java8推出了LongAdder。

可重⼊锁的意思:可以对⼀个锁对象多次执⾏lock()加锁和unlock()释放锁,每次枷锁就+1释放锁就-1
AQS(AbstractQueuedSynchronizer:抽象队列同步器),使⽤AQS能简单且⾼效地构造出⼤量的同步器,
ReentrantLock是可重入锁,内部包含了⼀个AQS对象,
当线程1进来加锁会将AQS内部的一个核心变量state(默认0)+1,并记录加锁线程(默认null),
当线程1再次进来加锁判断加锁线程是否是自己然后就可用对state进行累加1,
此时线程2尝试加锁发现state!=0且加锁线程也不是自己,就会进入AQS的一个等待队列,
等待线程1释放完锁后会将加锁线程设置为null,此时就可以使用AQS进行操作state从0变为1,
加锁线程设置为线程2,所以AQS还有一个等待队列存放哪些加锁失败的线程。
ReentrantLock默认是非公平锁, ReentrantLock lock = new ReentrantLock(true)才是公平锁。

微服务的注册与发现:读写锁
	在有⼈往服务注册表⾥写数据的时候,就不让其他⼈写了,同时也不让其他⼈读！
然后,有⼈在读服务注册表的数据的时候,其他⼈都可以随便同时读,但是此时不允许别⼈写
服务注册表数据了！我们就不应该暴⼒的加⼀个 synchronized,让所有读写线程全部串⾏化,那样
会导致并发性⾮常的低。⼀旦有⼈在写服务注册表数据,我们加个写锁,此时别⼈不能写,也不能读。
那么如果有⼈在读数据此时就可以让别⼈都可以读,但是不允许任何⼈写。其实⼤部分时候都是读操作,
所以使⽤读锁可以让⼤量的线程同时来读数据,不需要阻塞不需要排队,保证⾼并发读的性能是⽐较⾼的。
然后少量的时候是有服务上线要注册数据,写数据的场景是⽐较少的,
此时写数据的时候只能⼀个⼀个的加写锁然后写数据,同时写数据的时候就不允许别⼈来读数据了,所以读写锁是⾮常适合这种读多写少的场景的。


-----------------------------------------------------------

往 MQ ⾥写⼊的数据是⾮常核⼼及关键的,绝对不容许有丢失,如果⼀旦 MQ 中间件故障,那么这个系统⽴⻢就会把核⼼数据写⼊本地磁盘⽂件。
但是如果说在⾼峰期并发量⽐较⾼的情况下,接收到⼀条数据⽴⻢同步写本地磁盘⽂件,这个性能绝对是极其差的。
我们的核⼼思路是⼀旦 MQ 中间件故障求不是⽴⻢写本地磁盘,⽽是采⽤内存双缓冲 + 批量刷磁盘的机制。
系统接收到⼀条消息就会⽴⻢写内存缓冲,然后开启⼀个后台线程把内存缓冲的数据刷新到磁盘上去。

如果投递出去的消息在⽹络传输过程中丢失,或者在 RabbitMQ 的内存中还没写⼊磁盘的时候宕机,都会导致⽣产端投递到 MQ 的数据丢失。
⽽且丢失之后⽣产端⾃⼰还感知不到,同时还没办法来补救。所以⽣产端需要开启⼀个 confirm 模式,接收投递到 MQ的消息,
如果 MQ ⼀旦将消息持久化到磁盘之后,必须也要回传⼀个 confirm 消息给⽣产端。

开辟两块内存空间,也就是经典的内存双缓冲机制。
然后核⼼数据进来全部写第⼀块缓冲区,写满了之后,由⼀个线程进⾏那块缓冲区的数据批量
刷到磁盘⽂件的⼯作,其他线程同时可以继续写另外⼀块缓冲区。
⼀块缓冲区刷磁盘的同时,另外⼀块缓冲区可以接受其他线程的写⼊。
针对写内存多线程写入需加锁,但是直接加一个锁必然导致所有的线程都是串行,会大大降低性能。
因此在这⾥必须要对内存双缓冲机制引⼊分段加锁机制,也就是将内存缓冲切分为多个分⽚,
每个内存缓冲分⽚就对应⼀个锁:
DoubleBuffer doubleBufferSlice = doubleBuffer.chooseRandom();//从一个内存缓冲分片集合中选一个自动负载均衡
synchronized(doubleBufferSlice){
	doubleBufferSlice.write(data);
	if(doubleBufferSlice.isFull()){
		doubleBufferSlice.exchange();//缓存区1写满了则让缓存区2提供写服务
	}
}
doubleBufferSlice.flush();//将缓冲区的数据刷入内存(若放入同步代码块则写缓存区1满会继续持锁执行刷磁盘操作导致其他线程写缓存阻塞)


-----------------------------------------------------------

使⽤缓存集群的时候,最怕的就是热 key、⼤ value 这两种情况,热 key就是你的缓存集群中的某个 key 瞬间被数万甚⾄⼗万的并发请求打爆。
⼤ value就是你的某个 key 对应的 value 可能有 GB 级的⼤⼩,导致查询 value 的时候导致⽹络相关的故障问题。 以至于使用集群部署的
Redis也会因为单个从节点扛不住崩掉,大量的数据再通过查数据库写缓存到另一个从节点而继续击溃他,最后导致整个集群崩掉。
所以,此时完全可以基于⼤数据领域的流式计算技术来进⾏实时数据访问次数的统计,⽐如发现⼀秒之内,某条数据突然访问次数超过
了 1000,就直接⽴⻢把这条数据判定为是热点数据,可以将这个发现出来的热点数据写⼊⽐如 zookeeper 中。我们⾃⼰的系统可以对
zookeeper 指定的热点缓存对应的 znode 进⾏监听,如果有变化他⽴⻢就可以感知到了。
在每个系统内部其实还应该专⻔加⼀个对热点数据访问的限流熔断保护措施,每个系统实例每秒最多请求缓存集群读操作不超过多少次,
超过就可以熔断掉不让请求缓存集群,直接返回⼀个空⽩信息,然后⽤户稍后会⾃⾏再次重新刷新⻚⾯之类的。
通过系统层⾃⼰直接加限流熔断保护措施,可以很好的保护后⾯的缓存集群、数据库集群。

Eureka使用ConcurrentHashMap 将维护注册表、拉取注册表、更新⼼跳时间,全部发⽣在内存⾥！这是Eureka Server ⾮常核⼼的⼀个点。
数据库使用唯一索引保证幂等,主键id使用自增同时搭配UUID充当业务唯一id,
主键id可以通过索引提升排序效率、通过where id<#{id} limit#{} offset#{} 减小分页的结果集提升效率
读写分离:在如果对每个数据库服务器⼜是写⼊⼜是读取的话,会导致数据库服务器的 CPU 负载和 IO 负载⾮常的⾼
分库分表:当一个数据库的数据不断积累一般超过100W时会影响性能,通过hash计算将数据进行分库分表
数据的冷热分离:将今⽇实时计算出来的热数据放在 Rerdis 集群⾥,将历史冷数据放在另外⼀个 MySQL 集群⾥。
	然后开发⼀个数据查询平台,封装底层的多个 MySQL 集群,根据查询条件动态路由到热数据存储或者是冷数据存储。


-----------------------------------------------------------

RabbitMQ:他的好处在于可以⽀撑⾼并发、⾼吞吐、性能很⾼,同时有⾮常完善便捷的后台管理界⾯可以使⽤
	⽀持集群化、⾼可⽤部署架构、消息⾼可靠⽀持,功能较为完善,基于 erlang 语⾔开发需要较为扎实的 erlang 语⾔功底才可以定制化
RocketMQ:是阿⾥开源的,经过阿⾥的⽣产环境的超⾼并发、⾼吞吐的考验,性能卓越,同时还⽀持分布式事务等特殊场景。是基于 Java 语⾔开发的,适合深⼊阅读源码
Kafka:优势在于专为超⾼吞吐量的实时⽇志采集、实时数据同步、实时数据计算

以采⽤ MQ 中间件来实现系统解耦、异步调⽤、流量削峰,但是会带来系统可用性下降、消息一致性问题
RabbitMQ的消息的持久化:
	RabbitMQ⼀旦宕机就再次重启,就会丢失我们之前创建的queue,所以⾸先得先让queue是持久化的。
	还有⼀个重要的点,在你发送消息到RabbitMQ的时候,需要定义这条消息也是持久化的。
		这⾥要注意⼀点,RabbitMQ的消息持久化,是不承诺100%的消息不丢失的。
		因为有可能RabbitMQ接收到了消息在内存,但是还没来得及持久化到磁盘,他⾃⼰就宕机了,这个时候消息还是会丢失的。
		如果要完全100%保证写⼊RabbitMQ的数据必须落地磁盘,不会丢失,需要依靠其他的机制
			 消费者⼿动 ack机制保证消息不丢失,必须要消费者确保⾃⼰处理完毕了⼀个消息,
			才能⼿动发送ack 给 MQ,MQ 收到 ack 之后才会删除这个消息。
			RabbitMQ 投递消息的时候,都是会带上本次消息投递的⼀个 delivery tag 唯⼀标识⼀次消息投递。

			// false关闭autoACK
			channel.basicConsume(
				QUEUE_NAME, false, deliverCallback, consumerTag ->{}
			);
			DeliverCallback deliverCallback = (consumerTag, delivery) -> {
				try{
				// 发送消息
				} cahth {
					// 返回nack:true批量
					channeldelivery.basicAck(delivery.getEnvelope().getDeliveryTag(),true);
				} finally {
					// 返回ack:true尝试投递给其他消费者,false 的话会导致 RabbitMQ 知道你处理失败,但是还是删除这条消息
					channeldelivery.basicNack(delivery.getEnvelope().getDeliveryTag(),true);
				}
			}
			那么RabbitMQ 他能够⽆限制的不停给你的消费者服务实例推送uack消息吗?
			如果 RabbitMQ 给你的消费者服务实例推送的消息过多过快,那么此时这⼏千条消息都是 unack 的状态,
			⼀直积压着有可能会导致消费者服务实例 的内存溢出。RabbitMQ 基于⼀个 prefetch count	来控制
			unack message 的数量。你可以通过 “channel.basicQos(10)” 设置当前 channel 的 prefetch count。
			⽐如你要是设置为 10 的话,那么意味着当前这个 channel ⾥,unack message 的数量不能超过 10 个,
			以此来避免消费者服务实例积压 unack message 过多。
			RabbitMQ 官⽅给出的建议是 prefetch count ⼀般设置在 100~300之间,其实在我们的实践中,
			这个 prefetch count ⼤家完全是可以⾃⼰去压测⼀下的。
	集群化部署 + 数据多副本冗余
	必须得让⽣产者通过⼀些参数的设置,保证说写⼀条消息到某台机器,他必须同步这条消息到另外⼀台机器成功,
	集群⾥有双副本了,然后此时才可以认为这条消息写成功了。
	你的⽣产者同理应该基于参数设置⼀下,集群⾥必须有超过 2 台机器可以接收你的数据副本复制。

-----------------------------------------------------------

Kafka 是⾼吞吐低延迟的⾼并发、⾼性能的消息中间件,在⼤数据领域有极为⼴泛的运⽤。
写入内存--->刷入磁盘,以磁盘顺序写入末尾追加效率高
读内存不存在--->读磁盘然后放入内存中(零拷⻉技术直接将数据发送到网卡)


分布式架构下,系统之间传输数据,⼀个系统要确保⾃⼰给另外⼀个系统传输的数
据不会丢失必须要在指定时间内,收到另外⼀个系统 Quorum（⼤多数）数量(奇数/2+1)的机器响应说明写成功。
写给B系统的数据以异步方式,但是要同步等待Quorum数量的机器返回结果
while(true){
	// 设置一个健康是否发生FullGC的锚点
	long startWatch = currentTime();

	if(countAvailableResponse() > quorum){
		break;
	}

	long now = currentTime();
	if(now > expireTime){
		// 如果watchTime超过了1s说明发生了FullGC则expireTime续期,因为理论上上边的代码应该是微秒级的
		if(currentTime()- startWatch > 1000){
			expireTime += currentTime() - startWatch;
			continue;
		}

		// 指定时间内没有quorum个数量的机器返回结果,A强依赖B,B挂了A可以连带停机
		System.exit(1);
	}
	// 假设此时发生JVM FullGC会stop the world造成系统 A 内部的⼯作线程⼤量的卡顿
	Thread.sleep(1000);
}

MySQL主从复制:
	主库将变更写binlog日志，然后从库连接到主库之后，从库有一个IO线程，
	将主库的binlog日志拷贝到自己本地，写入一个中继日志中。
	从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，
	这样就可以保证自己跟主库的数据是一样的。
读写一致:
	从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行,
	在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。如果主库突然宕机，
	然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。
	所以mysql有两个机制:
		一个是半同步复制，用来解决主库数据丢失问题,需要等主从同步完成之后，主库上的写请求再返回 
	带来的后果就是主库的写请求时延会增加，吞吐量会降低。或借助中间件的路由作用，
	对服务层的读写请求进行分发，从而避免出现不一致问题，会带来成本上升。
		一个是并行复制，用来解决主从同步延时问题。


GC:
	对象将根据存活的时间被分为:年轻代（Young Generation）、年老代（Old Generation）、永久代（Permanent Generation，也就是方法区）
	年轻代(Young Generation):
		对象被创建时，内存的分配首先发生在年轻代(大对象可以直接被创建在年老代),
		大部分的对象在创建后很快就不再使用，因此很快变得不可达，
		于是被年轻代的GC机制清理掉,这个GC机制被称为Minor GC或叫Young GC。
		年轻代可以分为3个区域:Eden区和两个存活区(Survivor 0 、Survivor 1)
		绝大多数刚创建的对象会被分配在Eden区，其中的大多数对象很快就会消亡。
		Eden区是连续的内存空间，因此在其上分配内存极快；当Eden区满的时候，
		执行Minor GC，将消亡的对象清理掉，并将剩余的对象复制到一个存活区Survivor0
		(此时，Survivor1是空白的，两个Survivor总有一个是空白的)
		由于绝大部分的对象都是短命的，甚至存活不到Survivor中，
		所以，Eden区与Survivor的比例较大，HotSpot默认是 8:1。此后，每次Eden区满了，
		就执行一次Minor GC，并将剩余的对象都添加到Survivor0；当Survivor0也满的时候，
		将其中仍然活着的对象直接复制到Survivor1，以后Eden区执行Minor GC后，
		就将剩余的对象添加Survivor1（此时，Survivor0是空白的）。当两个存活区切换了几次
		(HotSpot虚拟机默认15次，用-XX:MaxTenuringThreshold控制，大于该值进入老年代)
		之后，仍然存活的对象（其实只有一小部分，比如，我们自己定义的对象），将被复制到老年代。
		Eden区是连续的空间，且Survivor总有一个为空。经过一次GC和复制，一个Survivor中保存着当前还活 着的对象，而Eden区和另一个Survivor区的内容都不再需要了，可以直接清空，
		到下一次GC时，两个Survivor的角色再互换。这种垃圾回收的方式就是著名的“停止-复制（Stop-and-copy）”清理法
	年老代(Old Generation):对象如果在年轻代存活了足够长的时间而没有被清理掉
		(即在几次YoungGC后存活了下来），则会被复制到年老代，年老代的空间一般比年轻代大，
		能存放更多的对象，在年老代上发生的GC次数也比年轻代少。当年老代内存不足时， 将执行Major GC，也叫 Full GC。
		如果对象比较大（比如长字符串或大数组），Young空间不足，则大对象会直接分配到老年代上
		(大对象可能触发提前GC，应少用，更应避免使用短命的大对象)老年代存储的对象比年轻代多得多，而且不乏大对象，
		对老年代进行内存清理时，如果使用停止-复制算法，则相当低效。一般，老年代用的算法是标记-整理算法，
		即：标记出仍然存活的对象（存在引用的），将所有存活的对象向一端移动，以保证内存的连续。
     	在发生Minor GC时，虚拟机会检查每次晋升进入老年代的大小是否大于老年代的剩余空间大小，
     	如果大于，则直接触发一次Full GC
 	方法区(永久代):
 		永久代的回收有两种:常量池中的常量，无用的类信息，常量的回收很简单，没有引用了就可以被回收
	在新生代采用的停止复制算法中，“停 止（Stop-the-world）”的意义是在回收内存时，需要暂停其他所 有线程的执行。这个是很低效的，现在的各种新生代收集器越来越优化这一点，但仍然只是将停止的时间变短，并未彻底取消停止。



378
